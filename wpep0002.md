| Key | Value |
| ---: | :--- |
| **Title** | Improve distributed capabilities |
| **Number** | 0002 |
| **Date** | 2019-10-21 |
| **Authors** | Frederic Lepied <flepied@wazo.io>, Mehdi Abaakouk <mabaakouk@wazo.io> |
| **Status** | proposed |

## Abstract

Redesign the way services find each other and their configurations.

## Motivation

To be able to cope with container deployments like Kubernetes, Swarm
or docker-compose as well as distributed deployments on VM or bare
metal, the startup sequences of the services need to be more dynamic
without anything being done at install time.

## Proposition

Use Consul to discover services and settings.

While the needed services are not started (nothing in Consul), the
service should wait for them to start and publish their information.

If a service needs a database, it should manage it at startup: create
it if it doesn't exist and do the modifications if a database schema
change is needed.

The setup of the services themselves like RabbitMQ in cluster mode,
load balancing database is out of scope of this proposition. What is
exposed by this proposition is only the URI of the service not the way
it has been deployed.

To summarize, nothing should be done by the packages or the Ansible
installer at install time that is deployment specific. For example, at
install time, we must not generate SSL certs, create or manipulate
databases or set any deployment specific parameter.

For non Consul aware services like Asterisk, Kamailio, RTPEngine or
PostgreSQL, we have 2 options. First one is to create a wrapper which
is interfacing with Consul to publish the state and get the needed
parameters. The second option is to write a plugin for the projects
that support it like Asterisk or Kamailio to interface with Consul.

### Details

#### Locating a Consul server

All the services, plugins and wrappers that are Consul aware must use
the `WAZO_CONSUL_HOST`, `WAZO_CONSUL_PORT` and `WAZO_CONSUL_SCHEME`
environment variables to find a Consul server to start their
initialization. If these environment variables are not available,
these variables can also be found in `/etc/wazo-platform/consul`. The
default values are the following if nothing is set:

* `WAZO_CONSUL_HOST`: consul
* `WAZO_CONSUL_PORT`: 8500
* `WAZO_CONSUL_SCHEME`: http

In systemd mode (VM or bare-metal), the systemd service file could have
a statement like this to source the variables:

```
EnvironmentFile=/etc/wazo-platform/consul
```

This file will be created by the Ansible installer to reflect the
location of the Consul server in systemd mode using the
`wazo_consul_host`, `wazo_consul_port` and `wazo_consul_scheme`
Ansible variables.

#### SSL certificates

The SSL certificates for the internal API can be stored in Consul and
each service can get them at startup. Following
https://www.consul.io/docs/connect/


## Updating existing applications

We have two use-cases to consider:

### 1. Loading the configuration when application start

Applications current just read yaml files and convert it into python dict.
This is done without any data validation and/or data type coercion.
After, the config dict is passed through the whole application, and each parts
will pick item they want.

A PoC https://github.com/wazo-platform/xivo-lib-python/pull/37 add a helper to
convert configuration stored in consul key/value storage into the expected yaml
format. It leverages the special wazo '!exec' yaml tag to load this yaml into
the application automatically.

The PoC have shown some issue, since there is no data validation and date type
coercion, and configuration values in consul is stored as bytes, only
configuration key that expect string as value worked.
Also the PoC does not support when a list is expected as value.

#### Ideas/Thought

* We first need something to validate and coerce the configuration by creating
  Schemas of what we expect (with voluptuous/marshmallow/pydantic/...)

* Instead of reading configuration directly from consul, we can read also it
  from environment variables and use `envconsul` to convert consul key/value in
  environment variables.
  This is a really good and generic solution, the makes our applications
  friendly with any system that generates environment for us.
  For `Systemd` based deployment we can create the EnvironmentFile=/etc/default/wazo-XXXXX with `envconsul`
  For `docker-compose` deployment we can create .env file with `envconsul`
  For `Kubenetes` deployment we can generates the `ConfigMap` with `consul-template`

  It's not fully compatible with use-cases 2.

  But this get us all containers orchestration restart/update features of these
  tools for free.

https://github.com/hashicorp/envconsul
https://github.com/hashicorp/consul-template

### 2. Updating the configuration dynamically at runtime.

It's clear that not all configurations can be reloaded at runtime.

Most of the configuration is used when the application starts (ip/port binding,
ssl certificates, rabbit and postgres settings, enabled plugins, etc...).
The application start instantiates many Python class (http/database/bus
clients/helpers) that uses this configuration and passed them around making
hard to change them at runtime.

Also we need to be able to detect when something is changed. python-consul
provides watch ability on key/value store.
If a configuration option is always read from the config dict built at startup,
the application will automatically use the new value, but for all others we
have specific code to write support them.

#### Ideas/Thought

* Most of configuration does not worse the cost of writing specific code, like
  changing ip/port of postgres/rabbit/http layers that will interrupt the
  services anyways as an application/containers restart we do.

* Don't support dynamic configuration change within the application, and just
  restart the application/container when the configuration is updated. This
  makes the applications more kubernetes/docker-compose friendly, especially if
  we choice to support only configuration loading from environment variables as
  this tools already provides smart solution for containers restart (see
  use-cases 1. ideas).

* Takes configuration option one by one and tests them (by write new
  integration/unit tests) and tag them as supported to be mutable.

  An abstraction layer for our configuration files would help a lot for
  tracking this, validate/coerce values, centralize the consul watching and
  signaling mechanism, etc...
